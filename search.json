[{"title":"Things Learned from Creating the Blog","date":"2021-08-29T06:36:11.000Z","url":"/08/29/2021/20210829-techniquesharing-things-learned-from-creating-blog/","tags":[["Code","/tags/Code/"],["Tech","/tags/Tech/"],["Long-Article","/tags/Long-Article/"]],"categories":[["Technique Sharing","/categories/Technique-Sharing/"]],"content":" This Blog is created based on GitHub webpage, and powered by Hexo. Hexo is an open source Blog personal blog framework which allow people to build their own Blog. I believe there are a lot of introduction of how to build personal blog with Hexo on GitHub, but I still want to share the process that how I build my personal blog with that. Start my own Blog – Build Blog with Hexo:PreparationBecause I’m using Windows system on my personal laptop, so I will particularly introduce the way to build the blog with Windows system locally and deploy it on GitHub In order to start a new blog with Hexo on GitHub, we need to install Node.js first which allow us to install Hexo with npm and create a new GitHub Repositories with [Your GitHub Name].github.io as the Repositories name And after that, you should add it into PATH After download Hexo, you can select a folder to initialize you own Blog locally with: After that, you will have some files in the folder, plz don’t push those files into your GitHub Repositories, the only thing you need to do is change the _config.yml file’s deploy with: You may notice that the repository block above should be the Webpage that you can clone your GitHub code, I’m using SSH to clone and push the code, and I also recommend you to use it: After change the settings on .yml file, we can push the website into the GitHub page with: "},{"title":"Machine Learning NoteBook 0817","date":"2021-08-17T06:16:46.000Z","url":"/08/17/2021/20210817-research-machinelearning-research-notebook/","tags":[["Code","/tags/Code/"],["Notebook","/tags/Notebook/"],["MachineLearning","/tags/MachineLearning/"]],"categories":[["Research","/categories/Research/"],["Machine Learning","/categories/Research/Machine-Learning/"]],"content":" 8/17: done 9:00 - 10:00 testing the model 10:00 - 11:30 nothing happened 1:00 - 4:00 finish the main figure 1 current status the result from yesterday have a large fluctuation, so we retrain the model with a lower lr: need to do tomorrownoticefigures and reference for paper table for draw the figure on after each step the molecular and sequence remain: step description data mol seq 0 original 2278226 986143 8005 1 drop multichain 2169710 944576 7850 2 only keep data with $K_i$ value 490605 204901 3404 3 calculate the number of time that molecular and sequence occur, remove data with molecular occur less than 3 times and sequence occur less than 6 times 288115 55924 1872 4 remove invalid $K_i$ value(e.g. $K_i$ = 0) 250481 54216 1846 5 embed molecular and sequence, remove the data which cannot be embedded 250344 54177 1844 6 remove $pK_i(log10 K_i)$ with higher than $8$ 249517 54135 1844 the figure: "},{"title":"Machine Learning NoteBook 0816","date":"2021-08-16T08:26:34.000Z","url":"/08/16/2021/20210816-research-machinelearning-research-notebook/","tags":[["Code","/tags/Code/"],["Notebook","/tags/Notebook/"],["MachineLearning","/tags/MachineLearning/"]],"categories":[["Research","/categories/Research/"],["Machine Learning","/categories/Research/Machine-Learning/"]],"content":" 8/6: done 9:00 - 12:00 finish the figure of inner test start to do outer test but preform not well 1:00 - 4:00 test the PDB Binding database and find that the accuracy is still increasing and start to train the model again 4:00 - 4:40 revise the inner test figures and data + start the training of model with changing lr 4:40 - 6:00 working on the result part 8:00 - 11:00 train the model, and find a problem in the result, solving current status finish the model again do the inner test with a better precise way do the outer test with PDB binding database need to do tomorrow solve the problem: notice you can use scheduler to help optimizer have a better performance, but it needs to change a lot of things you can check the change of lr with: figures and reference for paper figure: the performance of inner test(fig.1) table: the detail value of the inner test(table.1) Test Set $R$ $RMSE$ $MAE$ $R^2$ $MSE$ Inner Test – 149 0.81 0.87 0.65 0.66 0.75 Inner Test – 199 0.83 0.83 0.62 0.69 0.69 Inner Test – 249 0.84 0.82 0.61 0.70 0.67 Inner Test – 289 0.85 0.80 0.59 0.72 0.64 "},{"title":"Machine Learning NoteBook 0815","date":"2021-08-15T05:10:10.000Z","url":"/08/15/2021/20210815-research-machinelearning-research-notebook/","tags":[["Code","/tags/Code/"],["Notebook","/tags/Notebook/"],["MachineLearning","/tags/MachineLearning/"]],"categories":[["Research","/categories/Research/"],["Machine Learning","/categories/Research/Machine-Learning/"]],"content":" 8/15: done 3:00-5:00 – finish the data description part 5:00-6:00 – add some details of model design into the modeling part of method 8:00-10:40 – restart to train the model current status everything need to do again need to do tomorrow check the status of the model noticefigures and reference for paper"},{"title":"Machine Learning NoteBook 0813","date":"2021-08-13T13:15:45.000Z","url":"/08/13/2021/20210813-research-machinelearning-research-notebook/","tags":[["Code","/tags/Code/"],["Notebook","/tags/Notebook/"],["MachineLearning","/tags/MachineLearning/"]],"categories":[["Research","/categories/Research/"],["Machine Learning","/categories/Research/Machine-Learning/"]],"content":" 8/13: to-do draw figures for the prediction with different epochs the outer test set runs not quite well, try to use other datasets instead current status finish the test with outer test set, but find some problems that the accuracy is not that good trying to use some other sets to do the test: KiBA – Processing DAVIS – Waiting may not include $K_i$ value refine data statistic step description data 0 original 2278226 1 drop multichain 2169710 2 only keep data with $K_i$ value 490605 3 calculate the number of time that molecular and sequence occur, remove data with molecular occur less than 3 times and sequence occur less than 6 times 288115 4 remove invalid $K_i$ value(e.g. $K_i$ = 0) 250481 5 embed molecular and sequence, remove the data which cannot be embedded 250343 6 remove $pK_i(log10 K_i)$ with higher than $8$ 249517 need to do tomorrownotice a new python package is found to download data: homepage for download data use: split is a dictionary with 3 keys: &quot;train&quot; &quot;test&quot; &quot;valid&quot; each key is a pd.DataFrame figures and reference for paper+ | epoch | test r^2 | | —- | —- | | nan | nan |"},{"title":"Machine Learning NoteBook 0811","date":"2021-08-11T06:18:28.000Z","url":"/08/11/2021/20210811-research-machinelearning-research-notebook/","tags":[["Code","/tags/Code/"],["Notebook","/tags/Notebook/"],["MachineLearning","/tags/MachineLearning/"]],"categories":[["Research","/categories/Research/"],["Machine Learning","/categories/Research/Machine-Learning/"]],"content":" 8/11: to-do the model cannot be saved – retrain the model current status finished the first version of method and introduction need to do tomorrow compare the result from 0 to 600 epochs draw the figures for paper notice warning cannot be shown in the nohup, pls use print instead figures and reference for paper this is the distribution of the length of protein this is the distribution of the length of sequence "},{"title":"Machine Learning NoteBook 0810","date":"2021-08-10T07:25:13.000Z","url":"/08/10/2021/20210810-research-machinelearning-research-notebook/","tags":[["Code","/tags/Code/"],["Notebook","/tags/Notebook/"],["MachineLearning","/tags/MachineLearning/"]],"categories":[["Research","/categories/Research/"],["Machine Learning","/categories/Research/Machine-Learning/"]],"content":" 8/10: to-do finish the training of model version 5 which keep training until manually stop (make some graphs) start a new training for classification continue working on method current status the 4th version of model already preform quite well in the inter-test set: according to the test, $r^2$ value is $0.74$ almost hit the $0.75$, but it starts to have potential of overfitting Because the 4th version of model stop at 200 epochs and I forgot to save the $r^2$ value for training set. So, I start a new training with 2000 epochs and show the status in real-time with TensorBoard and also start to save the model every 100 epoch. need to do tomorrow evaluate the new model and draw figures with the model notice start to use TensorBoard in the code, so when you want to check the figures, pls use ssh to translate the port first with: notice: when starting the TensorBoard don’t forget to use --logdir=dir to set the dir which save the data when run the code with nohup the full sentence should be: figures and reference for paper NaN "},{"title":"Machine Learning NoteBook 0809","date":"2021-08-09T09:18:21.000Z","url":"/08/09/2021/20210809-research-machinelearning-research-notebook/","tags":[["Code","/tags/Code/"],["Notebook","/tags/Notebook/"],["MachineLearning","/tags/MachineLearning/"]],"categories":[["Research","/categories/Research/"],["Machine Learning","/categories/Research/Machine-Learning/"]],"content":" 8/9: to-do finish the improved network do some statistically evaluate on the first version of model and find the problems in data current status start to use the model with build 2 resnet blocks and a starting block for each of mol and seq each block contain 2 Conv1d module and the starting block will have 1 more Conv1d module with 1*1 core the first version of network is finished the model is overfitting try to add the $p$ value in dropout find a problem that the $Ki$ value in data have some extreme values try to remove those values and train the model again download the PDB database to evaluate the model(may need to change another database) already start to write the method’s data part, finished the Ki figure: (this is another version, the original version cannot be founded) need to do tomorrow make a to-do list for everything need to do tomorrow check the performance of the new model continue working on the Paper’s introduction and conclusion start to make some figures include the statistic of protein sequence data and molecular data notice during the network, you should add nn.BatchNorm1d() after each layer if nn.Linear figures and reference for paper figure is shown above "},{"title":"Machine Learning Notebook 0806","date":"2021-08-06T06:36:11.000Z","url":"/08/06/2021/20210806-research-machinelearning-research-notebook/","tags":[["Code","/tags/Code/"],["Notebook","/tags/Notebook/"],["MachineLearning","/tags/MachineLearning/"]],"categories":[["Research","/categories/Research/"],["Machine Learning","/categories/Research/Machine-Learning/"]],"content":" the first attempt of the network fix the problem to processing too slow(with embedding the sequence first) do not use DataFrame in building the DataLoader, translate DataFrame into tensor before put into DataLoader add normalization layer after ReLU need to do tomorrow check the embedding results improve the network accuracy notice when building the CNN part of the network, should add normalization layer every time after Conv don’t put DataFrame into DataSet figures and reference for paper about the data: the statistic review of protein length(exclude a single data larger than 7k) x label: protein sequence length y label: number of sequence "},{"title":"about","date":"2021-08-28T15:43:14.000Z","url":"/about/index.html","categories":[[" ",""]]},{"date":"2021-09-12T16:52:35.487Z","url":"/friends/index.html","categories":[[" ",""]]},{"date":"2021-09-12T16:49:43.117Z","url":"/tags/index.html","categories":[[" ",""]]},{"date":"2021-09-12T16:52:27.658Z","url":"/categories/index.html","categories":[[" ",""]]},{"date":"2021-09-12T17:27:39.136Z","url":"/search/index.html","categories":[[" ",""]]}]